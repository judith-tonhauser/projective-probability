\@doanenote {1}
macro:->Factive
predicates
were
also
taken
to
be
distinguished
by
syntactic
properties
in
\citealt
{kiparsky-kiparsky70}.
We
ignore
syntax
here
because
\citet
[fn.3]{kiparsky-kiparsky70}
already
pointed
out
that
syntactic
and
semantic
factivity
are
not
perfectly
aligned:
{\em
know}
and
{\em
realize},
for
instance,
were
taken
to
be
syntactically
nonfactive
but
semantically
factive.
For
recent
discussion
see
\citealt
{white-rawlins-nels2018},
\citealt
{djaerv-thesis},
and
references
therein.
\@endanenote 
\@doanenote {2}
macro:->For
instance,
according
to
\citealt
[66f.]{beaver01},
\citealt
[119-123]{gazdar79a}
`describes
the
inferences
associated
with
factive
verbs
$[$\dots
$]$
as
being
indefeasible
in
simple
affirmative
sentences',
that
is,
`entailments'.
And
\citet
[139]{schlenker10},
in
discussing
CCs,
pointed
to
`the
pattern
of
inference
which
is
characteristic
of
presuppositions:
an
entailment
of
the
positive
sentence
is
preserved
under
negation
and
in
questions'.
Authors
are
not
always
clear
about
which
definition
they
subscribe
to.
For
instance,
\citet
[355]{ccmg90}
used
{\em
realize}
to
illustrate
that
`[a]
sentence
can
both
entail
and
presuppose
another
sentence':
{\em
Joan
realizes
that
syntax
deals
with
sentence
structure}
`both
entails
and
presupposes'
({\em
ibid.})
that
syntax
deals
with
sentence
structure.
It
is
not
clear,
however,
whether
they
assumed
this
pattern
for
factive
predicates
more
generally
or
whether
they
assumed
that
a
predicate
is
factive
as
along
as
its
CC
is
presupposed.
\@endanenote 
\@doanenote {3}
macro:->A
content
$c$
is
an
entailment
of
sentence
S
if
and
only
if
$c$
is
the
case
whenever
S
is
true,
that
is,
if
and
only
if
$c$
is
indefeasibly
implied
by
S.
For
instance,
the
content
that
Sam
has
a
cat
is
an
entailment
of
the
sentence
{\em
Sam
has
a
white
cat}.
A
hallmark
of
presupposed
content
is
projection:
A
content
$c$
is
a
presupposition
if
$c$
is
typically
implied
by
an
utterance
of
S
as
well
as
by
utterances
of
so-called
family-of-sentences
variants
of
S,
including
the
polar
question
variant
of
S
or
the
negation
of
S
(see
e.g.\
\citealt
[\S
3.1]{ccmg90}).
For
instance,
the
content
that
Sam
has
a
parrot
is
typically
implied
not
just
by
an
utterance
of
the
sentence
{\em
Sam's
parrot
is
loud},
but
also
by
utterances
of
the
polar
question
variant
{\em
Is
Sam's
parrot
loud?}
and
the
negated
variant
{\em
Sam's
parrot
isn't
loud}.
(See
section
\ref
{s12}
for
how
to
distinguish
presuppositions
from
conventional
implicatures,
another
type
of
projective
content.)
From
the
definitions
of
presupposed
and
entailed
content,
and
from
the
ways
in
which
projection
and
entailment
are
diagnosed,
it
follows
that
presupposed
content
may,
but
need
not
be
entailed,
and
entailed
content
may,
but
need
not
be,
presupposed.
Thus,
content
that
is
implied
by
an
unembedded
sentence
may
be
merely
entailed,
merely
presupposed,
or
both
entailed
and
presupposed.
\@endanenote 
\@doanenote {4}
macro:->One
exception
are
\citet
{anand-hacquard2014},
who
suggested
(pp.74f.)
that
even
though
the
CC
of
predicates
like
{\em
acknowledge,
admit}
and
{\em
confirm}
projects,
the
CC
is
not
presupposed.
They
did
not,
however,
offer
a
diagnostic
for
distinguishing
projective
CCs
that
are
presupposed
from
projective
CCs
that
are
not
presupposed.
Ultimately,
their
argument
against
classifying
such
predicates
as
factive
rests
on
the
observation
that
their
CC
is
not
entailed.
\@endanenote 
\@doanenote {5}
macro:->According
to
\citealt
{kiparsky-kiparsky70}
and
\citealt
{karttunen71-implicative},
optionally
factive
predicates
include
{\em
anticipate,
acknowledge,
suspect,
report,
emphasize,
announce,
admit,
deduce},
and
{\em
remember};
this
last
predicate
is
taken
to
be
a
factive
predicate
in
other
research
(e.g.\
\citealt
{simons07,kastner2015,abrusan2016,karttunen2016,aravind-hackl2017,cremers2018});
in
\citealt
{karttunen-zaenen2005}
and
\citealt
{karttunen2016},
{\em
acknowledge,
admit},
and
{\em
confess}
are
considered
factive;
{\em
announce}
is
considered
nonfactive
in
\citealt
{karttunen-zaenen2005}.
\@endanenote 
\@doanenote {6}
macro:->Contrary
to
what
\citealt
{karttunen71b}
assumed,
nonprojection
of
the
CC
of
semifactive
predicates
is
possible
not
just
in
polar
questions
and
conditionals
(\citealt
{beaver-belly}).
\@endanenote 
\@doanenote {7}
macro:->We
assume
that
these
predicates
may
be
taken
to
be
optionally
factive
given
work
that
does
not
take
speakers
to
presuppose
the
truth
of
the
CC
of
these
predicates
(e.g.\
\citealt
{wyse,swanson2012,karttunen2016}).
\@endanenote 
\@doanenote {8}
macro:->\footnotesize
{\url
{https://www.quora.com/Has-a-doctor-ever-falsely-informed-you-that-you-re-dying}}
\@endanenote 
\@doanenote {9}
macro:->https://books.google.de/books?id=BnU1qPRO-34C,
p.66
\@endanenote 
\@doanenote {10}
macro:->We
thank
Manfred
Krifka
(p.c.)
for
pointing
out
this
example
to
us.
\@endanenote 
\@doanenote {11}
macro:->\citepos
{white-rawlins-nels2018}
MegaVeridicality
dataset
and
\citepos
{ross-pavlick2019}
VerbVeridicality
dataset
include
entailment
and
projection
ratings,
but
the
authors
did
not
present
by-predicate
analyses.
We
compare
the
MegaVeridicality
and
VerbVeridicality
ratings
to
our
data
in
sections
\ref
{s-converging1}
and
\ref
{s33}.
\citet
{djaerv-etal2016}
set
out
to
investigate
whether
emotive
and
cognitive
predicates
differ
in
whether
the
CC
is
entailed.
However,
because
the
predicates
in
their
stimuli
were
realized
in
polar
questions
(e.g.\
{\em
Is
Maria
aware
that
Mike
is
moving
back
to
Chicago?}),
it
is
not
clear
that
the
observed
differences
bear
on
whether
the
CC
is
entailed.
\@endanenote 
\@doanenote {12}
macro:->\citealt
{anand-hacquard2014}
assumed
that
{\em
demonstrate}
is
veridical,
in
contrast
to
\citealt
{anand-etal2019}.
This
latter
work
also
took
{\em
reveal}
to
be
nonfactive,
in
contrast
to,
for
instance,
\citealt
{egre2008,wyse}
or
\citealt
{tbd-variability}.
\@endanenote 
\@doanenote {13}
macro:->Different
categories
have
been
assumed
for
these
six
predicates.
\citet
{anand-hacquard2014}
took
{\em
confirm}
and
{\em
inform}
to
not
be
factive,
while
\citet
{schlenker10}
took
{\em
inform}
to
be
factive.
For
{\em
prove},
\citet
{white-rawlins-nels2018}
suggested
that
it
is
veridical
and
nonfactive,
but
\citet
{anand-hacquard2014}
took
it
to
be
nonveridical
and
nonfactive.
\citet
{swanson2012}
took
{\em
confess}
to
be
factive,
while
\citet
{karttunen2016}
only
took
it
to
commit
the
speaker
to
the
subject
of
the
attitude
being
committed
to
the
CC,
and
\citet
{wyse}
listed
it
under
the
nonfactive
predicates.
\citet
{swanson2012}
took
{\em
establish}
to
be
nonfactive,
but
\citet
{wyse}
listed
it
under
the
factive
predicates.
We
also
included
{\em
hear}:
even
though
it
is
often
considered
a
factive
predicate
(e.g.\
\citealt
{beaver-belly,anand-hacquard2014}),
{\em
hear}
also
has
a
nonfactive
reportative
evidential
sense
(see,
e.g.\
\citealt
{anderson86,simons07}),
especially
when
it
is
combined
with
complements
that
describe
events
that
cannot
be
auditorily
perceived,
as
in
our
experiments.
\@endanenote 
\@doanenote {14}
macro:->\label
{f-github}The
experiments,
data,
and
R
code
for
generating
the
figures
and
analyses
of
the
experiments
reported
in
this
paper
are
available
at
\url
{https://github.com/judith-tonhauser/projective-probability}.
All
experiments
were
conducted
with
IRB
approval.
Exps.~1b,
2b,
and
3b
were
preregistered:
\url
{https://osf.io/cxq47}.
\@endanenote 
\@doanenote {15}
macro:->For
other
diagnostics
for
projection
see,
e.g.\
\citealt
{smith-hall11,xue-onea11},
and
\citealt
{brst-lang11};
see
also
the
discussion
in
\citealt
{tbd-variability}.
\@endanenote 
\@doanenote {16}
macro:->Strictly
speaking,
gradient
certainty
ratings
reflect
gradience
in
the
degree
to
which
participants
\emph
{perceive}
the
speaker
to
be
committed
to
the
truth
of
the
content.
That
is,
as
in
any
experiment,
the
quantity
of
interest,
in
this
case
speaker
commitment,
is
only
indirectly
measured.
\@endanenote 
\@doanenote {17}
macro:->The
width
of
the
violin
at
any
given
point
represents
the
proportion
of
individual
participants'
ratings
located
at
that
point.
This
figure,
like
others
in
the
paper,
are
presented
in
color
in
the
electronic
version
of
this
article,
but
in
grayscale
in
the
print
version.
Color
versions
are
also
available
open
access
along
with
the
supplementary
materials
at
[INSERT
LINK
TO
HOSTING
SITE
AT
MUSE].

\@endanenote 
\@doanenote {18}
macro:->Choosing
an
arbitrary
numeric
threshold
for
factivity
is
also
complicated
by
the
fact
that
there
is
by-experiment
variation
in
mean
certainty
ratings.
For
instance,
the
mean
certainty
ratings
in
Exp.~1a
were
lower,
overall,
than
the
mean
certainty
ratings
in
\citepos
{tbd-variability}
Exps.~1.
For
example,
the
CC
of
{\em
be
annoyed},
which
was
the
most
projective
in
both
sets
of
experiments,
received
mean
certainty
ratings
of
.96
and
.92
in
\citepos
{tbd-variability}
Exps.~1a
and
1b,
respectively,
but
only
a
.86
in
our
Exp.~1a.
This
difference
may
be
due
to
the
fact
that
\citet
{tbd-variability}
primarily
investigated
highly
projective
content
whereas
our
Exp.~1a
included
a
wide
range
of
less
projective
content:
it
is
possible
that
participants'
certainty
ratings
were
influenced
by
the
overall
projection
of
the
contents
investigated.
\@endanenote 
\@doanenote {19}
macro:->Beta
regression
models
also
estimate
a
second
parameter,
namely
the
precision,
which
is
a
measure
of
dispersion:
the
greater
the
precision,
the
more
concentrated
the
ratings
are
around
the
mean.
In
this
paper,
we
rely
on
the
estimated
means
to
identify
whether
the
CCs
of
the
clause-embedding
predicates
differ
from
the
relevant
controls.
Both
the
estimated
mean
and
precision
for
each
predicate
are
reported
in
the
full
model
output
tables
in
Supplement
D.
\@endanenote 
\@doanenote {20}
macro:->A
Bayesian
mixed
effects
linear
regression
with
the
same
fixed
and
random
effects
structure
yielded
qualitatively
identical
results,
except
that
the
contrast
between
\emph
{pretend}
and
the
main
clause
controls
was
only
marginally
significant.
See
the
Github
repository
mentioned
in
footnote
\ref
{f-github}
for
the
model
code.
\@endanenote 
\@doanenote {21}
macro:->Exps.~1a,
2a,
and
3a
were
run
in
2017
and
2018,
whereas
Exps.~1b,
2b,
and
3b
were
run
in
2019.
Participants
in
the
later
experiments
were
paid
more
to
reflect
an
increased
minimum
wage
in
California.
\@endanenote 
\@doanenote {22}
macro:->Recall
that
participants
gave
binary
certainty
ratings,
with
`yes'
coded
as
1
and
`no'
coded
as
0.
To
increase
legibility,
these
ratings
are
jittered
vertically
and
horizontally
in
Figure
\ref
{f-projectivity2}
and
other
figures
like
it.
Consequently,
the
individual
certainty
ratings
should
not
be
read
against
the
y-axis.
\@endanenote 
\@doanenote {23}
macro:->According
to
\citealt
[1739]{spector-egre2015},
it
is
not
clear
whether
the
CC
of
{\em
say}
is
projective.
The
results
of
our
Exps.~1
suggest
that
it
is
weakly
projective.
\@endanenote 
\@doanenote {24}
macro:->We
re-plotted
the
data,
obtained
at
\url
{https://github.com/mcdm/CommitmentBank},
\url
{http://megaattitude.io}
and
\url
{https://github.com/alexisjihyeross/verb_veridicality},
respectively.
For
the
analysis
files,
see
the
GitHub
repository
mentioned
in
footnote
\ref
{f-github}.
\@endanenote 
\@doanenote {25}
macro:->\citealt
{demarneffe-etal-sub23}
found
that
a
model
that
predicts
certainty
ratings
from
factivity
captures
less
of
the
variance
than
a
model
that
predicts
certainty
ratings
from
predicate
lemma.
This
result
is
replicated
in
our
Exps.~1,
as
discussed
above.
\@endanenote 
\@doanenote {26}
macro:->A
Bayesian
mixed
effects
linear
regression
with
the
same
fixed
and
random
effects
structure
yielded
similar
results,
except
that
in
addition
to
{\em
prove}
and
{\em
be
right},
there
was
no
evidence
for
a
difference
between
the
entailing
controls
and
\emph
{know,
confirm,
discover},
and
{\em
see}.
See
the
Github
repository
mentioned
in
footnote
\ref
{f-github}
for
the
model
output.
\@endanenote 
\@doanenote {27}
macro:->A
Bayesian
mixed
effects
linear
regression
with
the
same
fixed
and
random
effects
structure
yielded
qualitatively
identical
results,
except
that
the
contrast
between
\emph
{be
right}
and
the
contradictory
controls
was
not
significant.
See
the
Github
repository
mentioned
in
footnote
\ref
{f-github}
for
the
model
output.
\@endanenote 
\@doanenote {28}
macro:->The
differences
in
the
results
of
Exps.~2
and
3
highlight
the
importance
for
future
research
to
investigate
the
validity
of
entailment
diagnostics.
While
the
ratings
were
overall
lower
with
the
contradictoriness
diagnostic
than
the
inference
diagnostic,
the
high
Spearman
rank
correlations
between
the
ratings
from
the
two
diagnostics---.954
for
the
two
gradient
measures
and
.934
for
the
two
categorical
measures---suggests
that
both
are
measuring
a
similar
underlying
concept.
Moreover,
the
entailed
controls
received
very
high
ratings
across
Exps.~2
and
3,
suggesting
that
all
four
measures
are
able
to
diagnose
entailed
content
with
some
reliability.
However,
\citet
[329]{demarneffe-etal2012}
have
suggested
that
veridicality
ratings
(comparable
to
our
inference
ratings)
are
influenced
by
pragmatic
reasoning;
see
also
\citealt
{pavlick-kwiatkowski2019}.
\@endanenote 
\@doanenote {29}
macro:->The
VerbVeridicality
dataset
does
not
include
projection
ratings
for
main
clause
content
to
which
the
projection
ratings
for
the
CCs
could
be
compared.
The
cutoff
of
a
mean
projection
rating
of
.3
(on
a
scale
from
-2
to
2)
is
arbitrary
but
comparable
to
the
mean
certainty
rating
of
.15
(on
a
scale
from
0
to
1)
for
{\em
pretend}
in
our
Exp.~1a.
\@endanenote 
\@doanenote {30}
macro:->\label
{mv}It
is
not
clear
that
the
CCs
of
these
97
predicates
are
entailed:
this
set
includes
{\em
inform}
(see
the
discussion
in
section
\ref
{s1})
as
well
as
the
communication
predicates
{\em
bitch}
and
{\em
howl},
whose
CCs
are
not
entailed.
For
instance,
it
does
not
follow
indefeasibly
from
the
naturally
occurring
example
with
{\em
bitch}
in
(i)
that
the
Democratic
party
hates
all
the
Jews.
\begin
{exe}
\exi
{(i)}
Rambling
to
reporters
in
the
Oval
Office,
Trump
bitched
that
the
Democratic
party
clearly
hates
all
the
Jews
because
of
all
the
support
reps
Rashida
Tlaib
and
Ilhan
Omar
received
after
he
strong
armed
the
Israelis
into
barring
them
from
visiting
the
country
as
members
of
Congress.
(\url
{https://www.wonkette.com/08-21-2019})
\end
{exe}

\@endanenote 
\@doanenote {31}
macro:->To
be
clear:
Contemporary
analyses
of
the
projection
of
the
CCs
of
factive
predicates
can
predict
the
nonprojection
of
factive
CCs
in
particular
utterances.
For
instance,
in
\citealt
{heim83}
and
\citealt
{vds92},
the
CC
is
locally
accommodated
when
its
projection
would
result
in
a
contradictory
or
uninformative
utterance.
Although
projection
of
the
CC
does
not
result
in
contradictory
or
uninformative
utterances
in
the
stimuli
in
our
Exps.~1,
one
might
assume,
as
suggested
by
an
anonymous
reviewer,
a)
that
some
participants
enrich
the
context
in
which
the
polar
question
stimuli
were
presented
with
information
that
does
result
in
a
contradiction
or
uninformativity,
and
b)
that
participants
are
more
likely
to
enrich
the
context
with
such
information
with
some
factive
predicates
than
others.
Under
these
assumptions,
these
analyses
may
be
compatible
with
the
results
of
our
Exps.~1,
namely
that
the
projection
of
the
CC
of
canonically
factive
predicates
is
heterogeneous
and
not
categorically
higher
than
that
of
other
predicates.
Neither
assumption,
however,
strikes
us
as
independently
motivated.
\@endanenote 
\@doanenote {32}
macro:->For
such
a
discussion
in
the
experimental
syntax
literature,
see
\citealt
{lau2014,
lau2017,
sprouse2007,
sprouse2013,
hofmeister2010,
keller2000,
sorace2005}.
\@endanenote 
\@doanenote {33}
macro:->The
Widely
Applicable
Information
Criterion
(WAIC)
is
a
measure
of
model
quality
that
estimates
the
pointwise
out-of-sample
prediction
accuracy
from
a
fitted
Bayesian
model
using
the
log-likelihood
evaluated
at
the
posterior
simulations
of
the
parameter
values
and
penalizes
models
with
more
parameters
over
models
with
fewer
\citep
{watanabe2010}.
We
obtained
WAIC
values
for
each
model
using
the
\texttt
{loo}
package
\citep
{vehtari2017}.
Lower
WAIC
values
indicate
better
models.
\@endanenote 
\@doanenote {34}
macro:->Models
were
fit
using
the
\texttt
{mclust}
and
\texttt
{mixtools}
packages
\citep
{benaglia2009,
scrucca2016}
in
R.
\@endanenote 
\@doanenote {35}
macro:->An
additional
problem:
for
simplicity
we
introduced
mixture
models
with
Gaussian
mixtures.
A
preliminary
investigation
of
the
data
from
Exp.~1a
via
mixture
models
suggests
that
15
of
the
20
predicates
are
best
characterized
by
3-6
components;
none
are
best
characterized
by
just
1
component
(see
Supplement
F).
However,
the
assumption
of
normality
made
by
Gaussian
mixture
models
does
not
hold
in
the
bounded
slider
ratings
data
of
Exp.~1a.
One
would
need
to
fit
mixtures
of
Beta
distributions,
for
which
statistical
inference
about
optimal
cluster
number
is
much
more
complex.
\@endanenote 
\@doanenote {36}
macro:->Similarly,
\citealt
{white2021}
recently
proposed
that
lexical
semantic
properties
other
than
factivity
may
be
implicated
in
another
domain
where
factivity
has
been
taken
to
play
a
role,
namely
whether
a
predicate
is
responsive.
\@endanenote 
